## 1. 几个生命周期：
**jsp生命周期：**

编译  -- 将jsp文件编译成servlet字节码文件

初始化 -- 实例化对应的servlet字节码文件（调用servlet的初始化方法）

使用 -- 使用jsp 调用对应servlet的service方法

销毁 -- 销毁jsp 销毁servlet实例

**bean生命周期：**

实例化 -- 为bean分配内存空间

依赖注入 -- 依赖注入

初始化 -- 执行切面的行为，比如前置通知，后置通知这些

使用 -- 使用bean

销毁 -- 销毁bean

**类加载的阶段：**

加载 -- 将字节码文件加载到虚拟机中

验证 -- 验证字节码文件的合法性

准备 -- 为类的成员变量分配空间

解析 -- 将符号引用解析为直接地址引用

初始化 -- 类加载最后的阶段，这个阶段的类加载完成，可以使用。

**vue的生命周期：**

beforeCreate  ： vue实例的挂载前，创建vue实例之前

created ： 创建实例成功，实现数据的异步请求

beforeMount ： 渲染dom之前

mounted ： 渲染dom完成

beforeUpdate ：重新渲染（数据更新需要重新渲染dom）

updated ：重新渲染完成

beforeDestory ： 销毁vue实例之前

destoryed ： 销毁完成

##  2. 阿里规约规范，数据模型规范
很多啊，举几个常用的规约：

1. 方法类型参数要一样，不要出现自动装箱和拆箱操作
2. 禁止使用存储过程
3. 使用equals方法要避免空指针
4. 事务出现异常要捕捉并回滚
5. 不要在finally中使用return 
6. 日志保存15天
7. 单元测试是非交互性，全自动执行的
8. 敏感数据要进行脱敏展示

## 3. 项目分层设计

## 4. 项目授权的设计

## 5.索引分类
聚簇索引  -- innodb引擎主键索引是聚簇索引，就是其数据文件和索引在同一个文件中

非聚簇索引 -- MyIsam引擎的主键索引是非聚簇索引，其索引文件和数据文件存放在不同文件中

普通索引

联合索引

唯一索引

主键索引

哈希索引  不支持范围查询 但是等值查询效率高于b+数

...

## 6. 数据库逻辑组成
mysql数据库体系架构： 连接层-服务层-引擎层
连接层主要工作是连接处理，授权认证，安全防护等。
服务层用于sql解析，sql优化，处理sql逻辑等
引擎层就是数据库存储数据的地方，负责数据的存储与提取。


## 7. 多少数据量分库分表
阿里java开发手册建议但表数据量超过500万行，或者单表数据容量超过2GB时，才进行分库分表。

## 8. 回表
当需要查询的数据列不能通过索引直接查出来时，数据库会进行回表操作。就是先根据索引查到匹配的数据行，找到这个数据行对应的主键id，然后进到主键索引中去查询需要的数据列。这个过程叫做回表。回表是一次磁盘IO，对查询性能有较大影响。
索引覆盖：
就是要查询的数据列刚好全部命中索引，这样就不需要进行回表，这种情况叫索引覆盖

## 9. sql优化

1. 尽量不要使用select*
2. 不要使用 in not in等关键字
3. 不要在索引列使用函数或计算
4. 不要在字段头部使用模糊匹配：%张
5. 不要使用!=
6. 查询时尽量走索引
7. 使用联合索引查询时，要符合最左前缀原则
8. 尽量使用小表驱动大表

## 10. 反射和自定义注解

反射是java提供的一种机制，他是java动态性的保证。反射机制的话，它允许你在程序运行时去获取类的相关属性，比如类的名字，类的参数，类的方法，还可以在程序运行过程中去调用方法。合理运用反射可以提高代码的灵活性。反射同时也是一些框架比如spring的底层实现之一。java通过反射获取类的方式我所了解的有以下几种：

1. ClassforName("com.xxx.xxx.class")
2. 类的实例.getClass()
3. xxx.class

自定义注解是java提供的工具，允许程序员自定义注解。工具位于java.lang包下

1. 通过@Target, @Retention , @interface等元注解创建一个自定义注解

2. 创建自定义注解处理器 通过反射获取对象，然后判断对象上是否有指定注解`method.isAnnotationPresent(MyAnnotation.class)` , 进行逻辑处理

3. 在测试类调用注解处理器


## 11. 判断索引使用情况
使用explain关键字解析sql语句，type =all表示全表扫描，ref表示使用了索引。 然后key是	实际使用的索引，如果是null表示没有使用索引。rows扫描的行数

## 12. 强制引用索引怎么做
使用force index(idx_name)来强制指定使用的索引。

## 13. 布隆过滤器
布隆过滤器是为了解决redis中缓存穿透的问题。缓存穿透指的是，用户请求的数据，在缓存中不存在，在数据库中也不存在。这样请求会绕过redis直接打到数据库上,造成数据库压力激增。

布隆过滤器解决了这一问题。布隆过滤器首先将数据通过多个hash算法算出值来，然后存放到值对应下标的二进制数组bucket中去。当需要取数据时，也是通过这些hash算法算值，算出来后去匹配数组中的二进制值，当所有的bucket中的值都是1时，说明这个数据是存在的。由于hash算法的缺陷，hash冲突是一定会发生的，因此布隆过滤器可能会出现误判的情况。但是这个误判的情况是可以认为调整的。我们只能尽量减小这个误判情况，但是不能消除。由于布隆过滤器基于hash算法和数组，因此其查询和添加效率非常高。

综上，在实际开发中，通常将数据库里的热点数据存入布隆过滤器里，外部请求获取数据时会首先经过布隆过滤器的依次筛选。如果请求的数据存在就从redis拿，否则直接丢弃请求。

## 14.  对ssm框架有什么看法？

ssm框架是一个强大的java应用开发的框架集合，是时下最为流行的框架集合，几乎每一个学习java的人都绕不开ssm。它包括spring,springmvc以及mybaits框架。

spring框架的话，它提供一个轻量级的容器，用于管理bean的生命周期和配置，提供bean的依赖注入功能。

springmvc是基于mvc架构的一个web应用开发框架，其提供了强大的web应用开发支持。

mybatis的话，它是一个基于java的持久层orm框架，它简化了我们同数据库的交互。

总的来说的话，ssm框架使开发人员的开发更简便高效，是时下最受欢迎的框架。

## 15. SpringMVC常用注解

1. @Controller
2. @RequestMapping
3. @RequestBody
4. @ResponseBody
5. @RequestParam
6. @RequestHeader 获取请求头信息
7. @CookieValue 获取cookie
8. @GetMapping, @PostMapping等

## 16. Linux常用命令

1. shutdown 关机
2. reboot 重启
3. sudo  高级权限
4. cd 进入
5. ls -l 展示
6. mv 移动
7. cp 复制
8. exit 推出进程
9. mkdir 创建目录
10. touch 创建并修改文件
11. cat 查看文件
12. nano 编辑器
13. vim  编辑器
14. find 查找
15. pwd  (print working directory) 
16. chmod 权限变更
17. mount  挂载磁盘
18. apt yum rpm wget 包管理器/下载工具
19. kill  杀死进程
20. ps  查看进程
21. nmtui  ( network management text user interface )

## 17.SQL常用聚合函数

1. max
2. min
3. avg
4. count
5. sum

## 18. Vue的基本原理

vue是一个轻量级的前端渐进式框架。它是基于MVVM架构设计的，vue中的数据会自动驱动视图。

MVVM指的是 model,view,viewmodel。  model 是模型，其实就是vue中data里的数据， view是视图，一般是html代码。
然后viewmodel是vue中的vm对象，它将model和view连接起来，负责把model中的数据同步到view中，同时把view中的数据同步到model中。 model和view通过viewmodel进行数据交互，这个过程是自动进行的，开发者只需要关注业务自身的逻辑就行了。


viewmodel实现双向数据绑定的核心原理是object.defineProperty()方法，它为对象添加了一个属性，并且可以监听这个属性的变化。vue会将data中的数据都注入一个get和set方法，用于监听数据的变化。当数据发生变化，会通知观察者，然后vue会生成新的dom树，对比旧dom树变化的节点，记录下来并修改到真是dom树中。

## 19. String常用方法
1. substring() 截取字符串
2. split() 字符串分割
3. indexOf() 查找字符串
4. charAt() 获取字符串
5. length() 长度
6. trim() 去除字符串两端空格
7. concat() 字符串连接
8. replace() 替换字符串
9. match() 匹配字符串
10. toLowerCase() 字符串转小写
11. toUpperCase() 字符串转大写
12. repeat() 重复字符串

## 20. mysql开窗函数

方便进行数据统计的函数

1. `row_number() `  为结果集中的每一行分配一个唯一的整数值，依据指定顺序分配
2. `rank()` 用法和`row_number()`一样 区别在于**`rank()`会为结果中的相同值分配同样的索引值**。
3. `over( partition by XXX order by XXX)`  指定开窗函数操作范围

`partition by`相当于`group by` ，是分组。`order by`是排序

以上语句作为一个列展示在结果表中。在具体使用中需要指定别名。

```sql
select *,row_number over(partition by deptno order by hiredate) index
from emp;
-- 
select *,avg(sal) over(partition by deptno order by hiredate) avg_sal
from emp;
```

## 21. redis数据一致性问题

#### 1. 什么时候会出现redis数据不一致的情况？

读写并发操作时会出现这种情况。在只读情况下不会出现

#### 2. 如何写数据？

写数据要注意的无非两点： 

1. **是直接更新数据还是删除数据再添加数据？** 

2. **是先操作数据库还是先操作redis？**

> 在生产过程中，更新redis缓存通常成本更高，因此常用的方法时删除redis缓存，再进行数据存入。

#### 3. 写数据先操作redis，再操作数据库

 ##### 一致性问题如何发生？

![](img\Snipaste_2023-11-10_10-15-41.png)

在多线程并发进行数据操作时，可能会出现数据不一致的情况，接下来具体分析一下：

1. 线程1需要修改数据， 首先将redis中的老数据删除掉，然后去修改数据库。在去修改数据库的过程中，出现了一些意外情况，产生了一些阻塞
2. 线程2此时此刻，在线程1还没有将数据库中的数据修改过来时，需要查询数据。于是去到redis中查数据，由于线程1已经删除了redis中的老数据，所以它发现redis没有，又去数据库中查。这样，线程2查到了数据库中还未被线程1修改的数据，也就是脏数据。线程2查到这个脏数据后就会将数据写入到redis中。这样，redis中就存了一个老数据/脏数据。

3. 此时线程1激活，不再阻塞，此时数据库中的老数据被修改为了新数据。

此时，出现了数据不一致的问题。即redis中存放的是老数据，但是数据库中存放的是新数据。因此，在之后如果有线程进行查询，都会查到老数据，直到该数据到期。

##### 如何解决？

想要解决这个一致性问题，使用延时双删。

双删指的是在线程1修改数据首先会去redis中删除一下，这是第一次删除。

线程1在修改完数据库中的数据后，再进行一次redis删除，这是第二次删除。

双删操作使得redis在修改数据库数据前后都保持空状态，这样如果其他线程想要查询数据，发现reids中没有，就会去数据库获取最新数据，然后写入redis中。

**为何要延时？**

思考一下，如果不进行延时双删，线程1在更新完数据库后立马删除redis数据，此时如果线程2还没有将从数据库中查询到的老数据写入redis中，那线程1不就删了个寂寞嘛？删了和没删一样。删完后，线程2再将老数据写入redis，那还是会导致数据一致性问题。**因此**，延时的目的是为了等待线程2把脏数据写入redis中再进行删除。延时延的就是这个线程2将脏数据写入redis的时间。这个时间具体根据业务情况来定，比如可以延迟个500ms等。

#### *4. 写数据先操作数据库，再操作redis

##### 这种方式可以最大限度来保证数据的最终一致性

![](img\Snipaste_2023-11-10_10-21-11.png)

1. 线程1要进行修改数据的操作，先将数据库中的数据修改为最新值
2. 当线程1还没有来得及进行删除操作时，线程2来执行查询操作，此时查询到的是一个脏数据。
3. 当线程1成功删除了redis老数据后，后续线程执行查询操作就是最新的数据了

我们不难发现，**这种方式不需要进行双删操作，也能保证数据最终一致性**。

> 先操作数据库还是redis？这个问题推荐先操作数据库，这样不需要进行双删操作，简化了业务。

#### 一些问题

实际上不管是先操作数据库还是先操作redis，都只能保证数据的最终一致性。我们无法保证数据的强一致性，想要这样做，就得加锁。但是加锁务必会降低效率，这似乎违背了我们使用redis的初衷。因此，在*性能*和*强一致性*之间，我们只能选择一个。

**另外**，考虑到可能删除redis数据这个操作也可能出现一些意外情况，比如删除失败。这样也会破坏数据一致性，所以我们可以引入**删除重试机制**。具体就是使用MQ来异步接收删除失败的请求，然后程序来监听这个MQ，进行删除重试操作。考虑到耦合性问题，还可以使用阿里的**canal框架**来解决这个问题。